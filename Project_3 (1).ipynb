{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Reading and Understanding the Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMgAkqaP+H4EwZbxe30IqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d5c78ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.parsers import read_csv\n",
    "import csv\n",
    "import random\n",
    "import os\n",
    "import matplotlib\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_list = list()\n",
    "\n",
    "data_dir = 'IMG'\n",
    "path = '/CarND-Behavioral-Cloning-P3/'\n",
    "data_csv = '~/CarND-Behavioral-Cloning-P3/driving_log.csv'\n",
    "\n",
    "df = pd.read_csv(data_csv, header=None,\n",
    "                names =['center','left', 'right', 'steering','throttle', 'brake'], index_col = False)\n",
    "#df['direction'] = pd.Series('s', index=df.index)\n",
    "steering = np.array(df.steering, dtype=np.float32)\n",
    "\n",
    "#yes_no2 = os.path.isfile('driving_log.csv')\n",
    "\n",
    "#print(yes_no2)\n",
    "\n",
    "with open('driving_log.csv', 'r') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader)\n",
    "    for row in reader:\n",
    "        center = row[0].strip()\n",
    "        left = row[1].strip()\n",
    "        right = row[2].strip()\n",
    "        steering = np.array(row[3], dtype=np.float32)\n",
    "        throttle = np.array(row[4], dtype=np.float32)\n",
    "        \n",
    "        if steering == 0:\n",
    "            if (np.random.rand() <= .35):\n",
    "                img_list.append([center, left, right, steering, throttle])\n",
    "        else:\n",
    "            img_list.append([center, left, right, steering, throttle])\n",
    "\n",
    "#print(img_list[3])\n",
    "\n",
    "histo = [x[3] for x in img_list]\n",
    "\n",
    "bins = 100\n",
    "plt.hist(histo, bins=bins)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_img_file(image):\n",
    "    image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "    #image = image/255.-.5\n",
    "    return image\n",
    "\n",
    "def brightness_image(image):\n",
    "    image_hsv = cv2.cvtColor(image,cv2.COLOR_RGB2HSV)\n",
    "    rnd_bright = 0.25+np.random.uniform()\n",
    "    image_hsv[:,:,2] = image_hsv[:,:,2]*rnd_bright\n",
    "    image_RGB = cv2.cvtColor(image_hsv, cv2.COLOR_HSV2RGB)\n",
    "    return image_RGB\n",
    "\n",
    "def img_size(image): \n",
    "    output_col = 128\n",
    "    output_row = 60\n",
    "    top_offset=.375 \n",
    "    bottom_offset=.125\n",
    "    top = int(top_offset * image.shape[0])\n",
    "    bottom = int(bottom_offset * image.shape[0])\n",
    "    image = cv2.resize(image[top:-bottom, :], (output_col, output_row),interpolation=cv2.INTER_AREA)\n",
    "    return image\n",
    "\n",
    "def flip_image(image, steering):\n",
    "    if random.randint(0, 1):\n",
    "        return cv2.flip(image, 1), -steering\n",
    "    else:\n",
    "        return image, steering\n",
    "    \n",
    "def shift_image(image, steering,shift_range):\n",
    "    rows = image.shape[0]\n",
    "    cols = image.shape[1]\n",
    "    shift_x = shift_range*np.random.uniform()-shift_range/2\n",
    "    steer_shift = steering + shift_x/shift_range*2*.2\n",
    "    shift_y = 10*np.random.uniform()-10/2\n",
    "    shift_dim = np.float32([[1,0,shift_x],[0,1,shift_y]])\n",
    "    shift_img = cv2.warpAffine(image, shift_dim, (cols, rows))\n",
    "    return shift_img, steer_shift \n",
    "\n",
    "def shift_practice(image, shift_range):\n",
    "    rows = image.shape[0]\n",
    "    cols = image.shape[1]\n",
    "    shift_x = shift_range*np.random.uniform()-shift_range/2\n",
    "    shift_y = 10*np.random.uniform()-10/2\n",
    "    shift_dim = np.float32([[1,0,shift_x],[0,1,shift_y]])\n",
    "    shift_img = cv2.warpAffine(image, shift_dim, (cols, rows))\n",
    "    return shift_img \n",
    "    \n",
    "def flip_practice_image(image):\n",
    "    if random.randint(0, 1):\n",
    "        return cv2.flip(image, 1)\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ind = 0\n",
    "f_name_c = df['center'][ind][4:] \n",
    "f_name_l = df['left'][ind][5:]\n",
    "f_name_r = df['right'][ind][5:]\n",
    "\n",
    "#img_l = cv2.imread(os.path.join(data_dir,f_name_c))\n",
    "#img_c = cv2.imread('IMG/center_2016_12_01_13_30_48_287.jpg')\n",
    "#plt.figure(figsize=(16,8))\n",
    "#plt.imshow(img_c)\n",
    "#plt.show()\n",
    "#yes_no1 = os.path.isfile('IMG/center_2016_12_01_13_30_48_287.jpg')\n",
    "#yes_no2 = os.path.isfile('driving_log.csv')\n",
    "#yes_no3 = os.path.isfile(os.path.join('IMG',f_name_c))\n",
    "#print (yes_no1, yes_no2, yes_no3)\n",
    "\n",
    "img_c = read_img_file(cv2.imread(os.path.join(data_dir, f_name_c)))\n",
    "img_l = read_img_file(cv2.imread(os.path.join(data_dir, f_name_l)))\n",
    "img_r = read_img_file(cv2.imread(os.path.join(data_dir, f_name_r)))\n",
    "img_c = shift_practice(img_c,150)\n",
    "img_c = brightness_image(img_c)\n",
    "img_c = np.array(img_c)\n",
    "img_c = img_size(img_c)\n",
    "img_c = flip_practice_image(img_c)\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(img_l)\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img_c)\n",
    "plt.axis('off')\n",
    "#plt.title('Steering Value: '+str(np.round(steering[ind])))\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(img_r)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "#print (img_c.shape[0],img_c.shape[1])\n",
    "print(f_name_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set = 3642\n",
      "Validation set = 1561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Shuffle img_list\n",
    "img_list = shuffle(img_list)\n",
    "\n",
    "#Split test img set\n",
    "train_set, valid_set = train_test_split(img_list, test_size=0.3, random_state=0)\n",
    "\n",
    "print(\"Train set =\", len(train_set))\n",
    "print(\"Validation set =\", len(valid_set))\n",
    "#print(train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Insert description of preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_data(input_data, indices):\n",
    "    steer_aug = 0.1\n",
    "    X = list()\n",
    "    y = list()\n",
    "    \n",
    "    for i in indices:\n",
    "        rnd = np.random.randint(0, 3)\n",
    "        name = input_data[i][rnd][4:]\n",
    "        image = cv2.imread(os.path.join(data_dir,name))\n",
    "        y_steer = input_data[i][3]\n",
    "        \n",
    "        if rnd ==1:\n",
    "            y_steer += steer_aug\n",
    "        elif rnd ==2:\n",
    "            y_steer -= steer_aug\n",
    "            \n",
    "        X.append(image)\n",
    "        y.append(y_steer)\n",
    "        \n",
    "    return X, y\n",
    "\n",
    "#X,y = load_data(train_set, int(50))\n",
    "#plt.imshow(X[0])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def generator(samples, batch):\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        \n",
    "        indicies = np.random.randint(0, len(samples), batch)\n",
    "        \n",
    "        X, y = load_data(samples, indicies)\n",
    "        \n",
    "        for i in range(batch):\n",
    "            image = X[i]\n",
    "            y_steer = y[i]\n",
    "            #image = cv2.imread(os.path.join(data_dir,path))\n",
    "            image = read_img_file(image)\n",
    "            image,y_steer = shift_image(image,y_steer,150)\n",
    "            image = brightness_image(image)\n",
    "            #image = np.array(image)\n",
    "            image,y_steer = flip_image(image, y_steer)\n",
    "            image = img_size(image)\n",
    "\n",
    "            X_batch.append(image)\n",
    "            y_batch.append(y_steer)\n",
    "            \n",
    "        yield np.array(X_batch), np.array(y_batch)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lambda_1 (Lambda)                (None, 60, 128, 3)    0           lambda_input_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_1 (Convolution2D)  (None, 60, 128, 24)   1824        lambda_1[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 30, 64, 24)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 30, 64, 36)    21636       maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 15, 32, 36)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 15, 32, 48)    43248       maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 7, 16, 48)     0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_4 (Convolution2D)  (None, 7, 16, 64)     27712       maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_5 (Convolution2D)  (None, 7, 16, 64)     36928       convolution2d_4[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 7168)          0           convolution2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 500)           3584500     flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 500)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 200)           100200      dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 200)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 10)            2010        dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             11          dense_3[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 3,818,069\n",
      "Trainable params: 3,818,069\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import models, optimizers, backend\n",
    "from keras.layers import Dense, Convolution2D, MaxPooling2D, Activation, Dropout, Flatten, Lambda\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "img_row = 60\n",
    "img_col = 128\n",
    "img_ch = 3\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(Lambda(lambda x: x/127.5 - .5, input_shape=(img_row, img_col, img_ch),output_shape=(img_row, img_col, img_ch)))\n",
    "model.add(Convolution2D(24, 5, 5, border_mode='same', input_shape=(img_row, img_col, img_ch), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(Convolution2D(36, 5, 5, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(Convolution2D(48, 5, 5, border_mode='same', activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dropout(.5))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "adam = Adam(lr=1e-04)\n",
    "model.compile(optimizer=adam, loss='mse')\n",
    "\n",
    "          \n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "\n",
    "Using the ADAM optimizer with a learning rate of 1e-4\n",
    "Because this is a continous regression problem we are using mean squared error and the loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "def save_model(model_json, h5):\n",
    "    json_string = model.to_json()\n",
    "    with open(model_json, 'w' ) as f:\n",
    "        json.dump(json_string, f)\n",
    "    model.save(h5)\n",
    "               \n",
    "    print('Model Saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\", line 429, in data_generator_task\n",
      "    generator_output = next(self._generator)\n",
      "StopIteration\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-10c7e7fd5c1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m                               \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                               nb_val_samples=sample_epoch_valid)\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mmodel_json\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'model_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    933\u001b[0m                                         \u001b[0mnb_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                                         \u001b[0mpickle_safe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpickle_safe\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                                         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m     def evaluate_generator(self, generator, val_samples,\n",
      "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1526\u001b[0m                                          \u001b[0;34m'(x, y, sample_weight) '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m                                          \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m                                          str(generator_output))\n\u001b[0m\u001b[1;32m   1529\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m                         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: output of generator should be a tuple (x, y, sample_weight) or (x, y). Found: None"
     ]
    }
   ],
   "source": [
    "#validation_gen = gen_valid(df)\n",
    "#validation_size = len(df)\n",
    "sm_limit = 1 \n",
    "batch = 50\n",
    "sample_epoch_train= 20000\n",
    "sample_epoch_valid= 2000\n",
    "n_epoch = 10\n",
    "\n",
    "i_best = 0 \n",
    "val_best = 1000\n",
    "\n",
    "for i in range(10): \n",
    "    fit = model.fit_generator(generator(train_set, batch), verbose =1,\n",
    "                              samples_per_epoch=sample_epoch_train,\n",
    "                              nb_epoch=n_epoch, \n",
    "                              validation_data=generator(valid_set, batch),\n",
    "                              nb_val_samples=sample_epoch_valid)\n",
    "    \n",
    "    model_json = 'model_' + str(i) + '.json'\n",
    "    h5 = 'model_' + str(i) + '.h5'\n",
    "    save_model(model_json,h5)\n",
    "    \n",
    "    val_loss = history.history['val_loss'][0]\n",
    "    if val_loss < val_best:\n",
    "        i_best = i\n",
    "        val_best = val_loss\n",
    "        model_json = 'model_best.json'\n",
    "        weights = 'model_best.h5'\n",
    "        save_model(model_json,weights)\n",
    "        \n",
    "    sm_limit = 1/(i+1)\n",
    "    \n",
    "#print('Best model found at iteration # ' + str(i_best))\n",
    "#print('Best Validation score : ' + str(np.round(val_best,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
